{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Set and the Domain Problem \n",
    "\n",
    "This dataset was originally posted on Kaggle. **The key task is to predict whether a product/part will go on backorder.**\n",
    "\n",
    "Product backorder may be the result of strong sales performance (e.g. the product is in such a high demand that production cannot keep up with sales). However, backorders can upset consumers, lead to canceled orders and decreased customer loyalty. Companies want to avoid backorders, but also avoid overstocking every product (leading to higher inventory costs).\n",
    "\n",
    "This dataset has ~1.9 million observations of products/parts in an 8 week period. The source of the data is unreferenced.\n",
    "\n",
    "* __Outcome__: whether the product went on backorder\n",
    "* __Predictors__: Current inventory, sales history, forecasted sales, recommended stocking amount, product risk flags etc. (22 predictors in total)\n",
    "\n",
    "The features and the target variable of the dataset are as follows:\n",
    "\n",
    "**Description**\n",
    "~~~\n",
    "# Features: \n",
    "sku - Random ID for the product\n",
    "national_inv - Current inventory level for the part\n",
    "lead_time - Transit time for product (if available)\n",
    "in_transit_qty - Amount of product in transit from source\n",
    "forecast_3_month - Forecast sales for the next 3 months\n",
    "forecast_6_month - Forecast sales for the next 6 months\n",
    "forecast_9_month - Forecast sales for the next 9 months\n",
    "sales_1_month - Sales quantity for the prior 1 month time period\n",
    "sales_3_month - Sales quantity for the prior 3 month time period\n",
    "sales_6_month - Sales quantity for the prior 6 month time period\n",
    "sales_9_month - Sales quantity for the prior 9 month time period\n",
    "min_bank - Minimum recommend amount to stock\n",
    "potential_issue - Source issue for part identified\n",
    "pieces_past_due - Parts overdue from source\n",
    "perf_6_month_avg - Source performance for prior 6 month period\n",
    "perf_12_month_avg - Source performance for prior 12 month period\n",
    "local_bo_qty - Amount of stock orders overdue\n",
    "deck_risk - Part risk flag\n",
    "oe_constraint - Part risk flag\n",
    "ppap_risk - Part risk flag\n",
    "stop_auto_buy - Part risk flag\n",
    "rev_stop - Part risk flag\n",
    "\n",
    "# Target \n",
    "went_on_backorder - Product actually went on backorder\n",
    "~~~\n",
    "\n",
    "Two data files for training and testing are accessible in the JupyterHub environment.\n",
    " \n",
    "<span style='background:yellow'>**NOTE:** The training data file is 117MB. **Do NOT add any data files to your commits** (training, test, or created), you may blow-through the _push limit_.</span>  \n",
    "You can easily lock up a notebook with bad coding practices.  \n",
    "Please save you project early, and often, and use `git commit` to checkpoint your process."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "--- \n",
    "### Overview / Roadmap\n",
    "\n",
    "**General steps**:\n",
    "* Part 1: Preprocessing\n",
    "  * Dataset carpentry & Exploratory Data Analysis\n",
    "    * Develop functions to perform the necessary steps, you will have to carpentry the Training and the Testing data.\n",
    "  * Generate a **smart sample** of the the data\n",
    "* Part 2: Training and Validation\n",
    "  * Create 3 alternative pipelines, each does:\n",
    "      * Anomaly detection\n",
    "      * Dimensionality reduction\n",
    "      * Classification\n",
    "* Part 3: Testing\n",
    "  * Train chosen model full training data\n",
    "  * Evaluate model against testing\n",
    "  * Write a summary of your processing and an analysis of the model performance\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# Part 1: Data Preprocessing\n",
    "\n",
    "In this part, we preprocess the given training set. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import os, sys\n",
    "import itertools\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.impute import SimpleImputer\n",
    "from imblearn.under_sampling import RandomUnderSampler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load dataset\n",
    "\n",
    "**Description**\n",
    "~~~\n",
    "sku - Random ID for the product\n",
    "national_inv - Current inventory level for the part\n",
    "lead_time - Transit time for product (if available)\n",
    "in_transit_qty - Amount of product in transit from source\n",
    "forecast_3_month - Forecast sales for the next 3 months\n",
    "forecast_6_month - Forecast sales for the next 6 months\n",
    "forecast_9_month - Forecast sales for the next 9 months\n",
    "sales_1_month - Sales quantity for the prior 1 month time period\n",
    "sales_3_month - Sales quantity for the prior 3 month time period\n",
    "sales_6_month - Sales quantity for the prior 6 month time period\n",
    "sales_9_month - Sales quantity for the prior 9 month time period\n",
    "min_bank - Minimum recommend amount to stock\n",
    "potential_issue - Source issue for part identified\n",
    "pieces_past_due - Parts overdue from source\n",
    "perf_6_month_avg - Source performance for prior 6 month period\n",
    "perf_12_month_avg - Source performance for prior 12 month period\n",
    "local_bo_qty - Amount of stock orders overdue\n",
    "deck_risk - Part risk flag\n",
    "oe_constraint - Part risk flag\n",
    "ppap_risk - Part risk flag\n",
    "stop_auto_buy - Part risk flag\n",
    "rev_stop - Part risk flag\n",
    "went_on_backorder - Product actually went on backorder. \n",
    "~~~\n",
    "\n",
    "**NOTE**: This is a real-world dataset without any preprocessing. There will also be warnings due to fact that the 1st column is mixing integer and string values. The last column, `went_on_backorder`, is what we are trying to predict.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/IPython/core/interactiveshell.py:3058: DtypeWarning: Columns (0) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>sku</th>\n",
       "      <td>3087333</td>\n",
       "      <td>2914585</td>\n",
       "      <td>1561268</td>\n",
       "      <td>2946534</td>\n",
       "      <td>1329894</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>national_inv</th>\n",
       "      <td>0.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>17.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lead_time</th>\n",
       "      <td>9.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>in_transit_qty</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>forecast_3_month</th>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>forecast_6_month</th>\n",
       "      <td>7.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>forecast_9_month</th>\n",
       "      <td>9.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sales_1_month</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sales_3_month</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sales_6_month</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sales_9_month</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min_bank</th>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>potential_issue</th>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pieces_past_due</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>perf_6_month_avg</th>\n",
       "      <td>0.7</td>\n",
       "      <td>-99.0</td>\n",
       "      <td>0.97</td>\n",
       "      <td>0.97</td>\n",
       "      <td>0.98</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>perf_12_month_avg</th>\n",
       "      <td>0.66</td>\n",
       "      <td>-99.0</td>\n",
       "      <td>0.94</td>\n",
       "      <td>0.93</td>\n",
       "      <td>0.98</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>local_bo_qty</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>deck_risk</th>\n",
       "      <td>No</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>oe_constraint</th>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ppap_risk</th>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>stop_auto_buy</th>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rev_stop</th>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>went_on_backorder</th>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         0        1        2        3        4\n",
       "sku                3087333  2914585  1561268  2946534  1329894\n",
       "national_inv           0.0     13.0     14.0     20.0     17.0\n",
       "lead_time              9.0      NaN      8.0      2.0      2.0\n",
       "in_transit_qty         0.0      0.0      0.0      0.0      0.0\n",
       "forecast_3_month       4.0      0.0      0.0      0.0      0.0\n",
       "forecast_6_month       7.0      0.0      0.0      0.0      0.0\n",
       "forecast_9_month       9.0      0.0      0.0      0.0      0.0\n",
       "sales_1_month          0.0      0.0      0.0      0.0      0.0\n",
       "sales_3_month          0.0      0.0      0.0      0.0      0.0\n",
       "sales_6_month          0.0      0.0      0.0      0.0      0.0\n",
       "sales_9_month          0.0      0.0      0.0      0.0      1.0\n",
       "min_bank               0.0      2.0      0.0      0.0      1.0\n",
       "potential_issue         No       No       No       No       No\n",
       "pieces_past_due        0.0      0.0      0.0      0.0      0.0\n",
       "perf_6_month_avg       0.7    -99.0     0.97     0.97     0.98\n",
       "perf_12_month_avg     0.66    -99.0     0.94     0.93     0.98\n",
       "local_bo_qty           0.0      0.0      0.0      0.0      0.0\n",
       "deck_risk               No      Yes       No       No      Yes\n",
       "oe_constraint           No       No       No       No       No\n",
       "ppap_risk               No       No       No       No       No\n",
       "stop_auto_buy          Yes      Yes      Yes      Yes      Yes\n",
       "rev_stop                No       No       No       No       No\n",
       "went_on_backorder       No       No       No       No       No"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# location of the training set; for Parts 1 and 2, \n",
    "# you only have access to this training data set for Parts 1 and 2 \n",
    "DATASET = '/dsa/data/all_datasets/back_order/Kaggle_Training_Dataset_v2.csv'\n",
    "assert os.path.exists(DATASET)\n",
    "\n",
    "# Load and shuffle\n",
    "dataset = pd.read_csv(DATASET).sample(frac = 1).reset_index(drop=True)\n",
    "\n",
    "dataset.head().transpose()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dataset.describe().transpose()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dataset.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dataset.apply(pd.Series.unique)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dataset.isna().mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# I notice that we have the -99 for perf_6_month_avg values\n",
    "# I also know we need to clean up national inv\n",
    "import matplotlib.pyplot as plt\n",
    "dataset['lead_time'].hist()\n",
    "#I ploted this becase I noticed the large jump/outliers. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "before shape       : (1687861, 23)\n"
     ]
    }
   ],
   "source": [
    "print(\"before shape       :\", dataset.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Processing\n",
    "\n",
    "In this section, the goal is to figure out:\n",
    "\n",
    "* which columns we can use directly,  \n",
    "* which columns are usable after some processing,  \n",
    "* and which columns are not processable or obviously irrelevant (like product id) that we will discard.\n",
    "\n",
    "Then process and prepare this dataset for creating a predictive model.\n",
    "\n",
    "**You can choose to employ any kind of approach for Exploratory Data Analysis to understand the data better. It is up to you to make the decisions regarding the cleaning/reencoding/dropping/imputing/binning etc.**  The following cells only serve as guidance. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1687861 entries, 0 to 1687860\n",
      "Data columns (total 23 columns):\n",
      " #   Column             Non-Null Count    Dtype  \n",
      "---  ------             --------------    -----  \n",
      " 0   sku                1687861 non-null  object \n",
      " 1   national_inv       1687860 non-null  float64\n",
      " 2   lead_time          1586967 non-null  float64\n",
      " 3   in_transit_qty     1687860 non-null  float64\n",
      " 4   forecast_3_month   1687860 non-null  float64\n",
      " 5   forecast_6_month   1687860 non-null  float64\n",
      " 6   forecast_9_month   1687860 non-null  float64\n",
      " 7   sales_1_month      1687860 non-null  float64\n",
      " 8   sales_3_month      1687860 non-null  float64\n",
      " 9   sales_6_month      1687860 non-null  float64\n",
      " 10  sales_9_month      1687860 non-null  float64\n",
      " 11  min_bank           1687860 non-null  float64\n",
      " 12  potential_issue    1687860 non-null  object \n",
      " 13  pieces_past_due    1687860 non-null  float64\n",
      " 14  perf_6_month_avg   1687860 non-null  float64\n",
      " 15  perf_12_month_avg  1687860 non-null  float64\n",
      " 16  local_bo_qty       1687860 non-null  float64\n",
      " 17  deck_risk          1687860 non-null  object \n",
      " 18  oe_constraint      1687860 non-null  object \n",
      " 19  ppap_risk          1687860 non-null  object \n",
      " 20  stop_auto_buy      1687860 non-null  object \n",
      " 21  rev_stop           1687860 non-null  object \n",
      " 22  went_on_backorder  1687860 non-null  object \n",
      "dtypes: float64(15), object(8)\n",
      "memory usage: 296.2+ MB\n"
     ]
    }
   ],
   "source": [
    "dataset.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Take samples and examine the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dataset.iloc[:3,:6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dataset.iloc[:3,6:12]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dataset.iloc[:3,12:18]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dataset.iloc[:3,18:24]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#While sku is not irrelevent, it is not helpful for modeling.\n",
    "dataset= dataset.drop(columns=['sku'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Drop columns that are obviously irrelevant or not processable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n",
      "No columns have zero variability\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>national_inv</th>\n",
       "      <th>lead_time</th>\n",
       "      <th>in_transit_qty</th>\n",
       "      <th>forecast_3_month</th>\n",
       "      <th>forecast_6_month</th>\n",
       "      <th>forecast_9_month</th>\n",
       "      <th>sales_1_month</th>\n",
       "      <th>sales_3_month</th>\n",
       "      <th>sales_6_month</th>\n",
       "      <th>sales_9_month</th>\n",
       "      <th>...</th>\n",
       "      <th>pieces_past_due</th>\n",
       "      <th>perf_6_month_avg</th>\n",
       "      <th>perf_12_month_avg</th>\n",
       "      <th>local_bo_qty</th>\n",
       "      <th>deck_risk</th>\n",
       "      <th>oe_constraint</th>\n",
       "      <th>ppap_risk</th>\n",
       "      <th>stop_auto_buy</th>\n",
       "      <th>rev_stop</th>\n",
       "      <th>went_on_backorder</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.70</td>\n",
       "      <td>0.66</td>\n",
       "      <td>0.0</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>13.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-99.00</td>\n",
       "      <td>-99.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>14.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.97</td>\n",
       "      <td>0.94</td>\n",
       "      <td>0.0</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>20.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.97</td>\n",
       "      <td>0.93</td>\n",
       "      <td>0.0</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>17.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.98</td>\n",
       "      <td>0.98</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   national_inv  lead_time  in_transit_qty  forecast_3_month  \\\n",
       "0           0.0        9.0             0.0               4.0   \n",
       "1          13.0        NaN             0.0               0.0   \n",
       "2          14.0        8.0             0.0               0.0   \n",
       "3          20.0        2.0             0.0               0.0   \n",
       "4          17.0        2.0             0.0               0.0   \n",
       "\n",
       "   forecast_6_month  forecast_9_month  sales_1_month  sales_3_month  \\\n",
       "0               7.0               9.0            0.0            0.0   \n",
       "1               0.0               0.0            0.0            0.0   \n",
       "2               0.0               0.0            0.0            0.0   \n",
       "3               0.0               0.0            0.0            0.0   \n",
       "4               0.0               0.0            0.0            0.0   \n",
       "\n",
       "   sales_6_month  sales_9_month  ...  pieces_past_due perf_6_month_avg  \\\n",
       "0            0.0            0.0  ...              0.0             0.70   \n",
       "1            0.0            0.0  ...              0.0           -99.00   \n",
       "2            0.0            0.0  ...              0.0             0.97   \n",
       "3            0.0            0.0  ...              0.0             0.97   \n",
       "4            0.0            1.0  ...              0.0             0.98   \n",
       "\n",
       "   perf_12_month_avg  local_bo_qty  deck_risk  oe_constraint ppap_risk  \\\n",
       "0               0.66           0.0         No             No        No   \n",
       "1             -99.00           0.0        Yes             No        No   \n",
       "2               0.94           0.0         No             No        No   \n",
       "3               0.93           0.0         No             No        No   \n",
       "4               0.98           0.0        Yes             No        No   \n",
       "\n",
       "  stop_auto_buy rev_stop went_on_backorder  \n",
       "0           Yes       No                No  \n",
       "1           Yes       No                No  \n",
       "2           Yes       No                No  \n",
       "3           Yes       No                No  \n",
       "4           Yes       No                No  \n",
       "\n",
       "[5 rows x 22 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Add code below this comment  (Question #E101)\n",
    "# ----------------------------------\n",
    "#Lets not drop rows are are not processable\n",
    "const = [c for c in dataset if dataset[c].nunique()==1]\n",
    "print(const)\n",
    "print('No columns have zero variability')\n",
    "dataset = dataset.drop(columns=const)\n",
    "dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>national_inv</th>\n",
       "      <th>lead_time</th>\n",
       "      <th>in_transit_qty</th>\n",
       "      <th>forecast_3_month</th>\n",
       "      <th>forecast_6_month</th>\n",
       "      <th>forecast_9_month</th>\n",
       "      <th>sales_1_month</th>\n",
       "      <th>sales_3_month</th>\n",
       "      <th>sales_6_month</th>\n",
       "      <th>sales_9_month</th>\n",
       "      <th>...</th>\n",
       "      <th>pieces_past_due</th>\n",
       "      <th>perf_6_month_avg</th>\n",
       "      <th>perf_12_month_avg</th>\n",
       "      <th>local_bo_qty</th>\n",
       "      <th>deck_risk</th>\n",
       "      <th>oe_constraint</th>\n",
       "      <th>ppap_risk</th>\n",
       "      <th>stop_auto_buy</th>\n",
       "      <th>rev_stop</th>\n",
       "      <th>went_on_backorder</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.70</td>\n",
       "      <td>0.66</td>\n",
       "      <td>0.0</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>13.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.85</td>\n",
       "      <td>0.83</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>14.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.97</td>\n",
       "      <td>0.94</td>\n",
       "      <td>0.0</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>20.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.97</td>\n",
       "      <td>0.93</td>\n",
       "      <td>0.0</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>17.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.98</td>\n",
       "      <td>0.98</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   national_inv  lead_time  in_transit_qty  forecast_3_month  \\\n",
       "0           0.0        9.0             0.0               4.0   \n",
       "1          13.0        8.0             0.0               0.0   \n",
       "2          14.0        8.0             0.0               0.0   \n",
       "3          20.0        2.0             0.0               0.0   \n",
       "4          17.0        2.0             0.0               0.0   \n",
       "\n",
       "   forecast_6_month  forecast_9_month  sales_1_month  sales_3_month  \\\n",
       "0               7.0               9.0            0.0            0.0   \n",
       "1               0.0               0.0            0.0            0.0   \n",
       "2               0.0               0.0            0.0            0.0   \n",
       "3               0.0               0.0            0.0            0.0   \n",
       "4               0.0               0.0            0.0            0.0   \n",
       "\n",
       "   sales_6_month  sales_9_month  ...  pieces_past_due perf_6_month_avg  \\\n",
       "0            0.0            0.0  ...              0.0             0.70   \n",
       "1            0.0            0.0  ...              0.0             0.85   \n",
       "2            0.0            0.0  ...              0.0             0.97   \n",
       "3            0.0            0.0  ...              0.0             0.97   \n",
       "4            0.0            1.0  ...              0.0             0.98   \n",
       "\n",
       "   perf_12_month_avg  local_bo_qty  deck_risk  oe_constraint ppap_risk  \\\n",
       "0               0.66           0.0         No             No        No   \n",
       "1               0.83           0.0        Yes             No        No   \n",
       "2               0.94           0.0         No             No        No   \n",
       "3               0.93           0.0         No             No        No   \n",
       "4               0.98           0.0        Yes             No        No   \n",
       "\n",
       "  stop_auto_buy rev_stop went_on_backorder  \n",
       "0           Yes       No                No  \n",
       "1           Yes       No                No  \n",
       "2           Yes       No                No  \n",
       "3           Yes       No                No  \n",
       "4           Yes       No                No  \n",
       "\n",
       "[5 rows x 22 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num = dataset.select_dtypes(include='number').columns #find all cpolumns with numbers\n",
    "dataset[num] = dataset[num].replace(-99, np.nan)\n",
    "imp = SimpleImputer(strategy='median')\n",
    "dataset[num] = imp.fit_transform(dataset[num])\n",
    "dataset.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Find unique values of string columns\n",
    "\n",
    "Now, try to make sure that the Yes/No columns really only contain Yes or No.  \n",
    "If that's true, proceed to convert them into binaries (0s and 1s).\n",
    "\n",
    "**Tip**: use [unique()](https://pandas.pydata.org/pandas-docs/stable/generated/pandas.Series.unique.html) function of pandas Series.\n",
    "\n",
    "Example\n",
    "\n",
    "~~~python\n",
    "print('went_on_backorder', dataset['went_on_backorder'].unique())\n",
    "~~~"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['potential_issue', 'deck_risk', 'oe_constraint', 'ppap_risk', 'stop_auto_buy', 'rev_stop', 'went_on_backorder']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "national_inv         [1024.0, 3.0, 255.0, 0.0, 8.0, 34.0, 74.0, 25....\n",
       "lead_time            [4.0, 2.0, 8.0, 0.0, 12.0, 9.0, 52.0, 3.0, 5.0...\n",
       "in_transit_qty       [28.0, 0.0, 24.0, 23.0, 160.0, 9.0, 13.0, 60.0...\n",
       "forecast_3_month     [900.0, 0.0, 1.0, 278.0, 25.0, 11.0, 2.0, 18.0...\n",
       "forecast_6_month     [900.0, 0.0, 12.0, 1.0, 500.0, 50.0, 11.0, 2.0...\n",
       "forecast_9_month     [900.0, 1.0, 0.0, 24.0, 728.0, 75.0, 11.0, 2.0...\n",
       "sales_1_month        [88.0, 0.0, 1.0, 7.0, 5.0, 3.0, 138.0, 6.0, 2....\n",
       "sales_3_month        [312.0, 0.0, 2.0, 14.0, 7.0, 289.0, 20.0, 10.0...\n",
       "sales_6_month        [625.0, 2.0, 0.0, 29.0, 9.0, 19.0, 540.0, 1.0,...\n",
       "sales_9_month        [924.0, 2.0, 0.0, 50.0, 14.0, 33.0, 745.0, 3.0...\n",
       "min_bank             [87.0, 0.0, 2.0, 6.0, 25.0, 50.0, 1.0, 3.0, 5....\n",
       "potential_issue                                         [No, Yes, nan]\n",
       "pieces_past_due      [0.0, 37.0, 208.0, 34.0, 3.0, 8.0, 16.0, 31.0,...\n",
       "perf_6_month_avg     [0.04, 0.91, 0.98, 0.77, 0.73, 0.94, 0.0, 0.83...\n",
       "perf_12_month_avg    [0.04, 0.95, 0.83, 0.62, 0.78, 0.97, 0.0, 0.7,...\n",
       "local_bo_qty         [0.0, 2.0, 7.0, 3.0, 1.0, 40.0, 10.0, 35.0, 42...\n",
       "deck_risk                                               [No, Yes, nan]\n",
       "oe_constraint                                           [No, Yes, nan]\n",
       "ppap_risk                                               [No, Yes, nan]\n",
       "stop_auto_buy                                           [Yes, No, nan]\n",
       "rev_stop                                                [No, Yes, nan]\n",
       "went_on_backorder                                       [No, Yes, nan]\n",
       "dtype: object"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# All the column names of these yes/no columns\n",
    "yes_no_columns = list(filter(lambda i: dataset[i].dtype!=np.float64, dataset.columns))\n",
    "print(yes_no_columns)\n",
    "\n",
    "# Add code below this comment  (Question #E102)\n",
    "# ----------------------------------\n",
    "#I acutally did this above!\n",
    "dataset.apply(pd.Series.unique)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You may see **nan** also as possible values representing missing values in the dataset.\n",
    "\n",
    "We fill them using most popular values, the [Mode](https://en.wikipedia.org/wiki/Mode_%28statistics%29) in Stats."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filling missing values of potential_issue with No\n",
      "Filling missing values of deck_risk with No\n",
      "Filling missing values of oe_constraint with No\n",
      "Filling missing values of ppap_risk with No\n",
      "Filling missing values of stop_auto_buy with Yes\n",
      "Filling missing values of rev_stop with No\n",
      "Filling missing values of went_on_backorder with No\n"
     ]
    }
   ],
   "source": [
    "for column_name in yes_no_columns:\n",
    "    mode = dataset[column_name].apply(str).mode()[0]\n",
    "    print('Filling missing values of {} with {}'.format(column_name, mode))\n",
    "    dataset[column_name].fillna(mode, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convert yes/no columns into binary (0s and 1s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add code below this comment  (Question #E103)\n",
    "# ----------------------------------\n",
    "dataset[yes_no_columns]=dataset[yes_no_columns].apply(lambda s: s.str.strip().str.upper().map({'YES':1,'NO':0}))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now all columns should be either int64 or float64."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import pandas.api.types as pt\n",
    "\n",
    "for c in num: # for all of the number columns (defined above)\n",
    "    if pt.is_float_dtype(dataset[c]):\n",
    "        v = dataset[c].dropna()\n",
    "        if np.all(v.mod(1)==0): #if remander exists\n",
    "            dataset[c] = dataset[c].astype('int32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1687861 entries, 0 to 1687860\n",
      "Data columns (total 22 columns):\n",
      " #   Column             Non-Null Count    Dtype  \n",
      "---  ------             --------------    -----  \n",
      " 0   national_inv       1687861 non-null  int32  \n",
      " 1   lead_time          1687861 non-null  int32  \n",
      " 2   in_transit_qty     1687861 non-null  int32  \n",
      " 3   forecast_3_month   1687861 non-null  int32  \n",
      " 4   forecast_6_month   1687861 non-null  int32  \n",
      " 5   forecast_9_month   1687861 non-null  int32  \n",
      " 6   sales_1_month      1687861 non-null  int32  \n",
      " 7   sales_3_month      1687861 non-null  int32  \n",
      " 8   sales_6_month      1687861 non-null  int32  \n",
      " 9   sales_9_month      1687861 non-null  int32  \n",
      " 10  min_bank           1687861 non-null  int32  \n",
      " 11  potential_issue    1687861 non-null  int64  \n",
      " 12  pieces_past_due    1687861 non-null  int32  \n",
      " 13  perf_6_month_avg   1687861 non-null  float64\n",
      " 14  perf_12_month_avg  1687861 non-null  float64\n",
      " 15  local_bo_qty       1687861 non-null  int32  \n",
      " 16  deck_risk          1687861 non-null  int64  \n",
      " 17  oe_constraint      1687861 non-null  int64  \n",
      " 18  ppap_risk          1687861 non-null  int64  \n",
      " 19  stop_auto_buy      1687861 non-null  int64  \n",
      " 20  rev_stop           1687861 non-null  int64  \n",
      " 21  went_on_backorder  1687861 non-null  int64  \n",
      "dtypes: float64(2), int32(13), int64(7)\n",
      "memory usage: 199.6 MB\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "national_inv         [1024, 3, 255, 0, 8, 34, 74, 25, 7, 17, 9, 231...\n",
       "lead_time            [4, 2, 8, 0, 12, 9, 52, 3, 5, 10, 16, 15, 6, 1...\n",
       "in_transit_qty       [28, 0, 24, 23, 160, 9, 13, 60, 58, 1, 2, 35, ...\n",
       "forecast_3_month     [900, 0, 1, 278, 25, 11, 2, 18, 300, 500, 7, 6...\n",
       "forecast_6_month     [900, 0, 12, 1, 500, 50, 11, 2, 36, 600, 974, ...\n",
       "forecast_9_month     [900, 1, 0, 24, 728, 75, 11, 2, 51, 1373, 19, ...\n",
       "sales_1_month        [88, 0, 1, 7, 5, 3, 138, 6, 2, 78, 52, 19, 76,...\n",
       "sales_3_month        [312, 0, 2, 14, 7, 289, 20, 10, 1, 15, 122, 3,...\n",
       "sales_6_month        [625, 2, 0, 29, 9, 19, 540, 1, 33, 32, 4, 28, ...\n",
       "sales_9_month        [924, 2, 0, 50, 14, 33, 745, 3, 44, 60, 6, 26,...\n",
       "min_bank             [87, 0, 2, 6, 25, 50, 1, 3, 5, 4, 80, 20, 63, ...\n",
       "potential_issue                                                 [0, 1]\n",
       "pieces_past_due      [0, 37, 208, 34, 3, 8, 16, 31, 50, 4, 1, 28, 7...\n",
       "perf_6_month_avg     [0.04, 0.91, 0.98, 0.77, 0.73, 0.94, 0.0, 0.83...\n",
       "perf_12_month_avg    [0.04, 0.95, 0.83, 0.62, 0.78, 0.97, 0.0, 0.7,...\n",
       "local_bo_qty         [0, 2, 7, 3, 1, 40, 10, 35, 42, 5, 55, 114, 44...\n",
       "deck_risk                                                       [0, 1]\n",
       "oe_constraint                                                   [0, 1]\n",
       "ppap_risk                                                       [0, 1]\n",
       "stop_auto_buy                                                   [1, 0]\n",
       "rev_stop                                                        [0, 1]\n",
       "went_on_backorder                                               [0, 1]\n",
       "dtype: object"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.info()\n",
    "dataset.apply(pd.Series.unique)\n",
    "# look at our types, we will fix this at the end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "perf_6_month_avg    -0.028626\n",
      "perf_12_month_avg   -0.028174\n",
      "lead_time           -0.018104\n",
      "potential_issue      0.014090\n",
      "deck_risk           -0.011691\n",
      "local_bo_qty         0.009504\n",
      "ppap_risk            0.008814\n",
      "Name: went_on_backorder, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "#Lets see how these variables are correlated to our target variable\n",
    "CorrList = dataset.corr()['went_on_backorder']\n",
    "SortCorrList = CorrList.drop('went_on_backorder').loc[CorrList.abs() > 0.005] # you can change this variable\n",
    "SortCorrList = SortCorrList.reindex(SortCorrList.abs().sort_values(ascending=False).index)\n",
    "\n",
    "print(SortCorrList)\n",
    "\n",
    "# In short, none of them are individually very correlated individually, but these are the most correlated. \n",
    "# These vectors should not be removed."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "                   !!!!!!!!!!!!!     We will use PCA INSTEAD of this method         !!!!!!!!!!!!!\n",
    "\n",
    "#Dropping correlated columns\n",
    "X = dataset.drop('went_on_backorder', axis=1)\n",
    "y = dataset['went_on_backorder']\n",
    "\n",
    "corr = dataset.corr().abs()\n",
    "upper = corr.where(np.triu(np.ones(corr.shape), 1).astype(bool))\n",
    "\n",
    "to_drop = set()\n",
    "for col in upper.columns:\n",
    "    # columns highly correlated with `col`\n",
    "    hi = upper.index[upper[col] > 0.9].tolist()\n",
    "    for dup in hi:\n",
    "        # choose which one to keep: keep the one that correlates more w/ target\n",
    "        keep = col if abs(dataset[col].corr(y)) >= abs(dataset[dup].corr(dataset[''])) else dup\n",
    "        drop = dup if keep == col else col\n",
    "        to_drop.add(drop)\n",
    "        \n",
    "print(to_drop)\n",
    "\n",
    "dataset.drop(columns=list(to_drop), inplace=True) \n",
    "\n",
    "# We are dropping the very very highly correlated columns, because their meaning is alread accounted for in other vectors.\n",
    "# This speeds up our compute time, without losing much information. \n",
    "# This may be a bad call, and in real life, I really dont know what I would do. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Smartly sample the data into a more manageable size for cross-validation \n",
    "\n",
    "\n",
    "This is a good point to re-balance dataset before actually moving on. For sampling, we can either take advantage of pandas/numpy `sample` method or use `imblearn` [package](https://imbalanced-learn.org/stable/user_guide.html#user-guide). \n",
    "\n",
    "\n",
    "Create a \"smart\", balanced sample: \n",
    "\n",
    " * it should be balanced: it is up to you if you do a 50/50 balance or anything else. \n",
    " * it should be manageable-sized: you will run a lot of cross validations in Part 2 that are very time consuming. \n",
    " * it should still reflect the characteristics of the original data.\n",
    " \n",
    "Use any approach you deem necessary to create the balanced sample. It will serve as your data set in the development.  \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "backorder ratio: 11293 / 1687861 = 0.006690716830355106\n"
     ]
    }
   ],
   "source": [
    "num_backorder = np.sum(dataset['went_on_backorder']==1)\n",
    "print('backorder ratio:', num_backorder, '/', len(dataset), '=', num_backorder / len(dataset))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a smart sample of the data and save it.  You can either store the data to csv files or simply use `joblib` to dump the variables and load them in Part 2. \n",
    "\n",
    "**Example code for using joblib:**\n",
    "\n",
    "Say we need to store three objects (sampled_X, sampled_y, model) to a file. \n",
    "\n",
    "```python\n",
    "import joblib\n",
    "\n",
    "# for dumping \n",
    "joblib.dump([sampled_X, sampled_y, model], 'data/sample-data-v1.pkl')\n",
    "\n",
    "# for loading\n",
    "sampled_X, sampled_y, model = joblib.load('data/sample-data-v1.pkl')\n",
    "\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = dataset.drop('went_on_backorder', axis=1)\n",
    "y = dataset['went_on_backorder']\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.30, random_state=69)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 1181502 entries, 1305420 to 1506358\n",
      "Data columns (total 21 columns):\n",
      " #   Column             Non-Null Count    Dtype  \n",
      "---  ------             --------------    -----  \n",
      " 0   national_inv       1181502 non-null  int32  \n",
      " 1   lead_time          1181502 non-null  int32  \n",
      " 2   in_transit_qty     1181502 non-null  int32  \n",
      " 3   forecast_3_month   1181502 non-null  int32  \n",
      " 4   forecast_6_month   1181502 non-null  int32  \n",
      " 5   forecast_9_month   1181502 non-null  int32  \n",
      " 6   sales_1_month      1181502 non-null  int32  \n",
      " 7   sales_3_month      1181502 non-null  int32  \n",
      " 8   sales_6_month      1181502 non-null  int32  \n",
      " 9   sales_9_month      1181502 non-null  int32  \n",
      " 10  min_bank           1181502 non-null  int32  \n",
      " 11  potential_issue    1181502 non-null  int64  \n",
      " 12  pieces_past_due    1181502 non-null  int32  \n",
      " 13  perf_6_month_avg   1181502 non-null  float64\n",
      " 14  perf_12_month_avg  1181502 non-null  float64\n",
      " 15  local_bo_qty       1181502 non-null  int32  \n",
      " 16  deck_risk          1181502 non-null  int64  \n",
      " 17  oe_constraint      1181502 non-null  int64  \n",
      " 18  ppap_risk          1181502 non-null  int64  \n",
      " 19  stop_auto_buy      1181502 non-null  int64  \n",
      " 20  rev_stop           1181502 non-null  int64  \n",
      "dtypes: float64(2), int32(13), int64(6)\n",
      "memory usage: 139.7 MB\n"
     ]
    }
   ],
   "source": [
    "X_train.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# I am unable to get SMOTE to work with my memory requirements. This also means that I will be unable to make oversampleing work\n",
    "#from imblearn.over_sampling import SMOTE\n",
    "#sm = SMOTE()\n",
    "#X_train, y_train = sm.fit_resample(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "#therefore I am using undersampling \n",
    "from sklearn.utils import resample\n",
    "df_tr = pd.concat([X_train, y_train], axis=1)\n",
    "maj = df_tr[df_tr.went_on_backorder == 0]\n",
    "min_ = df_tr[df_tr.went_on_backorder == 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "maj_down = resample(maj,\n",
    "                    replace=False,\n",
    "                    n_samples=len(min_),\n",
    "                    random_state=27)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    7912\n",
      "1    7912\n",
      "Name: went_on_backorder, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "df_down = pd.concat([maj_down, min_]) \\\n",
    "             .sample(frac=1, random_state=42) \\\n",
    "             .reset_index(drop=True)\n",
    "# check balance\n",
    "print(df_down.went_on_backorder.value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = df_down.drop('went_on_backorder', axis=1)\n",
    "y_train = df_down.went_on_backorder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before undersample: 0.006677080885300745\n",
      "After undersample: 0.5\n"
     ]
    }
   ],
   "source": [
    "#df_bal.info()\n",
    "\n",
    "print(f'Before undersample: {y_test.sum()/y_test.count()}')\n",
    "print(f'After undersample: {y_train.sum()/y_train.count()}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "**Note:** After sampling the data, you may want to write the data to a file for reloading later.\n",
    "\n",
    "<span style=\"background: yellow;\">If required, remove the `dataset` variable to avoid any memory-related issue.</span> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['testing-data.pkl']"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Write your smart, balanced sample to local file  \n",
    "# ----------------------------------\n",
    "import joblib\n",
    "joblib.dump([X_train, y_train], 'training-data.pkl')\n",
    "joblib.dump([X_test, y_test], 'testing-data.pkl')\n",
    "\n",
    "# I am not pickling a model yet, I thought this was to be done in part two!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "**Make commits often and definitely when done!**  \n",
    "Comment should be: `Final Project, Checkpoint - Data Sampled`\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save your notebook!\n",
    "## Then commit and push "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
