{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 3: Unbiased Evaluation using a New Test Set\n",
    "\n",
    "In this part, we are given a new test set that serves as the \"truly unseen data\" (`/dsa/data/all_datasets/back_order/Kaggle_Test_Dataset_v2.csv`). We can now take advantage of the entire smart sample that we created in Part I. \n",
    "\n",
    "* Load your best pipeline model and anomaly detector from Part 2. \n",
    "* Load your balanced (smart) sample deom Part 1. \n",
    "* Retrain the model with the entire balanced sample. (do NOT repeat the grid search)\n",
    "* Save the model. \n",
    "* Test it with the \"unseen\" data. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import modules as needed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "%matplotlib inline\n",
    "import random, time\n",
    "random.seed(10)\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import joblib\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.ensemble import RandomForestClassifier, IsolationForest\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn.pipeline import Pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Load the balanced sample and the best pipeline and the anomaly detector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(15824, 21)\n",
      "0    7912\n",
      "1    7912\n",
      "Name: went_on_backorder, dtype: int64\n",
      "iso model: IsolationForest(contamination=0.02, random_state=42)\n",
      "best pipe:   Pipeline(steps=[('sc', StandardScaler()),\n",
      "                ('pca',\n",
      "                 PCA(n_components=15, random_state=42,\n",
      "                     svd_solver='randomized')),\n",
      "                ('clf',\n",
      "                 RandomForestClassifier(max_depth=20, n_estimators=400,\n",
      "                                        n_jobs=-1))])\n"
     ]
    }
   ],
   "source": [
    "X_bal, y_bal = joblib.load('training-data.pkl')\n",
    "\n",
    "iso   = joblib.load('best_anomaly_detection.pkl')\n",
    "model = joblib.load('best_pipeline.pkl') \n",
    "\n",
    "print(X_bal.shape)\n",
    "print(y_bal.value_counts())\n",
    "\n",
    "\n",
    "print(\"iso model:\", iso)\n",
    "print(\"best pipe:  \", model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "##  Retrain pipeline using the full balanced sample \n",
    "\n",
    "Use the full balanced sample to train the pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "inlier_mask = iso.fit_predict(X_bal) == 1\n",
    "X_train = X_bal[inlier_mask]\n",
    "y_train = y_bal[inlier_mask]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pipeline(steps=[('sc', StandardScaler()),\n",
      "                ('pca',\n",
      "                 PCA(n_components=15, random_state=42,\n",
      "                     svd_solver='randomized')),\n",
      "                ('clf',\n",
      "                 RandomForestClassifier(max_depth=20, n_estimators=400,\n",
      "                                        n_jobs=-1))])\n"
     ]
    }
   ],
   "source": [
    "# Add code below this comment  (Question #E301)\n",
    "# ----------------------------------\n",
    "model.fit(X_train, y_train)\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pickle and save the trained model and the anomaly detector "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['final_models/pipeline_iso_pca_rf.pkl']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Add code below this comment  \n",
    "# -----------------------------\n",
    "\n",
    "joblib.dump(iso, \"final_models/iso_detector.pkl\")\n",
    "joblib.dump(model, \"final_models/pipeline_iso_pca_rf.pkl\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "---\n",
    "\n",
    "## Load the test data and evaluate your model\n",
    "\n",
    " * `/dsa/data/all_datasets/back_order/Kaggle_Test_Dataset_v2.csv`\n",
    "\n",
    "Remember:  \n",
    "* We need to preprocess this test data (**follow** the steps similar to Part I)\n",
    "\n",
    "\n",
    "* If you have fitted any normalizer/standardizer in Part 2, then you have to transform this test data using the same fitted normalizer/standardizer. Do NOT retrain anything. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/IPython/core/interactiveshell.py:3058: DtypeWarning: Columns (0) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>national_inv</th>\n",
       "      <th>lead_time</th>\n",
       "      <th>in_transit_qty</th>\n",
       "      <th>forecast_3_month</th>\n",
       "      <th>forecast_6_month</th>\n",
       "      <th>forecast_9_month</th>\n",
       "      <th>sales_1_month</th>\n",
       "      <th>sales_3_month</th>\n",
       "      <th>sales_6_month</th>\n",
       "      <th>sales_9_month</th>\n",
       "      <th>...</th>\n",
       "      <th>pieces_past_due</th>\n",
       "      <th>perf_6_month_avg</th>\n",
       "      <th>perf_12_month_avg</th>\n",
       "      <th>local_bo_qty</th>\n",
       "      <th>deck_risk</th>\n",
       "      <th>oe_constraint</th>\n",
       "      <th>ppap_risk</th>\n",
       "      <th>stop_auto_buy</th>\n",
       "      <th>rev_stop</th>\n",
       "      <th>went_on_backorder</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>62.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.85</td>\n",
       "      <td>0.83</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>9.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.85</td>\n",
       "      <td>0.83</td>\n",
       "      <td>0.0</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>17.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.92</td>\n",
       "      <td>0.95</td>\n",
       "      <td>0.0</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.78</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.0</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.54</td>\n",
       "      <td>0.71</td>\n",
       "      <td>0.0</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   national_inv  lead_time  in_transit_qty  forecast_3_month  \\\n",
       "0          62.0        8.0             0.0               0.0   \n",
       "1           9.0        8.0             0.0               0.0   \n",
       "2          17.0        8.0             0.0               0.0   \n",
       "3           9.0        2.0             0.0               0.0   \n",
       "4           2.0        8.0             0.0               0.0   \n",
       "\n",
       "   forecast_6_month  forecast_9_month  sales_1_month  sales_3_month  \\\n",
       "0               0.0               0.0            0.0            0.0   \n",
       "1               0.0               0.0            0.0            0.0   \n",
       "2               0.0               0.0            0.0            0.0   \n",
       "3               0.0               0.0            0.0            0.0   \n",
       "4               0.0               0.0            0.0            0.0   \n",
       "\n",
       "   sales_6_month  sales_9_month  ...  pieces_past_due perf_6_month_avg  \\\n",
       "0            0.0            0.0  ...              0.0             0.85   \n",
       "1            0.0            0.0  ...              0.0             0.85   \n",
       "2            0.0            0.0  ...              0.0             0.92   \n",
       "3            0.0            2.0  ...              0.0             0.78   \n",
       "4            0.0            0.0  ...              0.0             0.54   \n",
       "\n",
       "   perf_12_month_avg  local_bo_qty  deck_risk  oe_constraint ppap_risk  \\\n",
       "0               0.83           0.0        Yes             No        No   \n",
       "1               0.83           0.0         No             No       Yes   \n",
       "2               0.95           0.0         No             No        No   \n",
       "3               0.75           0.0         No             No       Yes   \n",
       "4               0.71           0.0         No             No        No   \n",
       "\n",
       "  stop_auto_buy rev_stop went_on_backorder  \n",
       "0           Yes       No                No  \n",
       "1            No       No                No  \n",
       "2           Yes       No                No  \n",
       "3           Yes       No                No  \n",
       "4           Yes       No                No  \n",
       "\n",
       "[5 rows x 22 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Preprocess the given test set  (Question #E302)\n",
    "# ----------------------------------\n",
    "\n",
    "df_test= pd.read_csv(\"/dsa/data/all_datasets/back_order/Kaggle_Test_Dataset_v2.csv\")\n",
    "\n",
    "\n",
    "#we need to replicate the preprocessing with this new dataset\n",
    "df_test = df_test.drop(columns=[\"sku\"])\n",
    "num_cols = df_test.select_dtypes(include=\"number\").columns\n",
    "df_test[num_cols] = df_test[num_cols].replace(-99, np.nan)\n",
    "imp = SimpleImputer(strategy=\"median\")\n",
    "df_test[num_cols] = imp.fit_transform(df_test[num_cols])\n",
    "df_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filling missing values of potential_issue with No\n",
      "Filling missing values of deck_risk with No\n",
      "Filling missing values of oe_constraint with No\n",
      "Filling missing values of ppap_risk with No\n",
      "Filling missing values of stop_auto_buy with Yes\n",
      "Filling missing values of rev_stop with No\n",
      "Filling missing values of went_on_backorder with No\n"
     ]
    }
   ],
   "source": [
    "# Do the yes no converstion\n",
    "yes_no_columns = list(filter(lambda i: df_test[i].dtype!=np.float64, df_test.columns))\n",
    "\n",
    "for column_name in yes_no_columns:\n",
    "    mode = df_test[column_name].apply(str).mode()[0]\n",
    "    print('Filling missing values of {} with {}'.format(column_name, mode))\n",
    "    df_test[column_name].fillna(mode, inplace=True)\n",
    "    \n",
    "df_test[yes_no_columns]=df_test[yes_no_columns].apply(lambda s: s.str.strip().str.upper().map({'YES':1,'NO':0}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Without Iso Forrest\n",
    "X_test = df_test.drop(\"went_on_backorder\",axis=1)\n",
    "y_test = df_test[\"went_on_backorder\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now predict and evaluate with the preprocessed test set. It would be interesting to see the performance with and without outliers removal from the test set. \n",
    "\n",
    "Report confusion matrix, precision, recall, f1-score, accuracy, and other measures (if any). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----- WITHOUT ISO FOREST  -----\n",
      "\n",
      "               No_Backorder  Yes_Backorder\n",
      "No_Backorder         197193          42195\n",
      "Yes_Backorder           692           1996\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      " No_Backorder       1.00      0.82      0.90    239388\n",
      "Yes_Backorder       0.05      0.74      0.09      2688\n",
      "\n",
      "     accuracy                           0.82    242076\n",
      "    macro avg       0.52      0.78      0.49    242076\n",
      " weighted avg       0.99      0.82      0.89    242076\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Add code below this comment  (Question #E303)\n",
    "# ----------------------------------\n",
    "# WITHOUT ISO FORREST\n",
    "\n",
    "print(\"----- WITHOUT ISO FOREST  -----\\n\")\n",
    "print(pd.DataFrame(\n",
    "    confusion_matrix(y_test, y_pred),\n",
    "    index=[\"No_Backorder\",\"Yes_Backorder\"],\n",
    "    columns=[\"No_Backorder\",\"Yes_Backorder\"]\n",
    "))\n",
    "print(classification_report(\n",
    "    y_test, y_pred,\n",
    "    target_names=[\"No_Backorder\",\"Yes_Backorder\"]\n",
    "))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#With Iso Forest\n",
    "mask_inlier = iso.predict(X_test) == 1\n",
    "X_in, y_in = X_test[mask_inlier], y_test[mask_inlier]\n",
    "y_in_pred = model.predict(X_in)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "----- WITH ISO FOREST  -----\n",
      "\n",
      "               No_Backorder  Yes_Backorder\n",
      "No_Backorder         193119          41345\n",
      "Yes_Backorder           677           1953\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      " No_Backorder       1.00      0.82      0.90    234464\n",
      "Yes_Backorder       0.05      0.74      0.09      2630\n",
      "\n",
      "     accuracy                           0.82    237094\n",
      "    macro avg       0.52      0.78      0.49    237094\n",
      " weighted avg       0.99      0.82      0.89    237094\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "print(\"\\n----- WITH ISO FOREST  -----\\n\")\n",
    "print(pd.DataFrame(\n",
    "    confusion_matrix(y_in, y_in_pred),\n",
    "    index=[\"No_Backorder\",\"Yes_Backorder\"],\n",
    "    columns=[\"No_Backorder\",\"Yes_Backorder\"]\n",
    "))\n",
    "print(classification_report(\n",
    "    y_in, y_in_pred,\n",
    "    target_names=[\"No_Backorder\",\"Yes_Backorder\"]\n",
    "))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.1103950825360631"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Base Case\n",
    "base_rate = y_test.mean()\n",
    "base_rate*100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Conclusion\n",
    "\n",
    "Comment on the performance of your model: take a look at the project notes to see what you should report here. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Write a summary of your processing and an analysis of the model performance  \n",
    "# (Question #E304)\n",
    "# ----------------------------------\n",
    "# I am also writing this for managment (sorry, I read the projects notes wrong)\n",
    "\n",
    "\n",
    "**My model has performed!**  \n",
    "Today, we have **no** system in place to anticipate back‐orders—every stock‐out comes as a surprise. By implementing this pipeline, we can shift from reactive firefighting to proactive planning.\n",
    "\n",
    "1. **Current State**  \n",
    "   - No systematic way to flag at-risk SKUs.  \n",
    "   - Stock-outs hurt customer satisfaction and increase expedited freight costs.\n",
    "\n",
    "2. **Future State**  \n",
    "   - Daily “heads-up” on likely back-order items.  \n",
    "   - Inventory planners can focus on a targeted list instead of scanning all 240 k SKUs.\n",
    "\n",
    "\n",
    "### What is my model?  \n",
    "A simple three-step pipeline:\n",
    "1. **StandardScaler** – scales each feature so none dominates.  \n",
    "2. **PCA (15 components)** – condenses 20+ features into 15 “super-features,” speeding up training.  \n",
    "3. **RandomForest** (400 trees, max depth 20) – an ensemble of decision trees votes on back-order risk.  \n",
    "\n",
    "> We tuned hundreds of hyperparameter combinations and saved the best version.\n",
    "\n",
    "\n",
    "### How does it perform on unseen data?  \n",
    "\n",
    "| Condition                               | Rate   |  \n",
    "|-----------------------------------------|--------|  \n",
    "| **Caught back-orders** (recall)         | 74 %   |  \n",
    "| **Missed back-orders** (false negatives)| 26 %   |  \n",
    "| **Correctly cleared** (specificity)     | 82 %   |  \n",
    "| **False alarms** (false positives)      | 18 %   |  \n",
    "| **Overall accuracy**                    | 82 %   |  \n",
    "\n",
    "> Outlier filtering via IsolationForest (2 % contamination) made **no difference**, so we’ve omitted it to keep things simple.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Reflection\n",
    "\n",
    "Imagine you are data scientist that has been tasked with developing a system to save your \n",
    "company money by predicting and preventing back orders of parts in the supply chain.\n",
    "\n",
    "Write a **brief summary** for \"management\" that details your findings, \n",
    "your level of certainty and trust in the models, \n",
    "and recommendations for operationalizing these models for the business. take a look at the project notes to see what you should report here. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Write your answer here:  \n",
    "# (Question #E305)\n",
    "# ----------------------------------\n",
    "**Model Certainty**\n",
    "\n",
    "- Recall: Catches 74% of true back-orders (1,987 / 2,688) vs. 0 % with no model.\n",
    "- Precision: Only 4% of alerts are true back-orders—a 4× lift over the 1.1 % raw rate. <-\n",
    "\n",
    "**Trade-offs & Model Limits**\n",
    "\n",
    "- Miss rate: 26% of real back-orders still slip through.\n",
    "- False-alarm rate: 96% of alerts (≈ 42,203) are noise.\n",
    "- Static view: Doesn’t capture seasonality, promotions, or sudden demand spikes.\n",
    "\n",
    "**Operational Recommendations**\n",
    "- Dedicated triage: Assign 1 FTE to vet ~20 k alerts/run and log outcomes.\n",
    "\n",
    "- Feature enhancement: Add supplier details to dataset.\n",
    "- Ongoing monitoring: Track recall/precision monthly; retrain quarterly.\n",
    "\n",
    "**Bottom Line**\n",
    "- Preventing 74% of 2,688 annual back-orders at 320 dollars each saves $636,518/year.\n",
    "- Even with 96 percent false alarms, a review process could yield net cost savings and happier customers.\n",
    "\n",
    "**Emphasis on Model improvement**\n",
    "- Focuse on reducing false alarms.\n",
    "- Re-evaulate loss function. (Currently focuses on catching all backorders, but needs to focus on false alarms)\n",
    "- Estimating the cost of each items backorder. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save your notebook!\n",
    "\n",
    "## Commit and push. \n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
